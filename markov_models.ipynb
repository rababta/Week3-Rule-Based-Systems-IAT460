{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0ZDRa7YWb6H"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAT-ComputationalCreativity-Spring2025/Week3-Rule-Based-Systems/blob/main/markov_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24wB42RJWb6J"
      },
      "source": [
        "# Markov Models Text Generation\n",
        "\n",
        "This notebook introduces Markov chains for text generation. We'll build a simple\n",
        "text generator that learns patterns from input text and generates new text with\n",
        "similar statistical properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fZbtM6w8Wb6J"
      },
      "outputs": [],
      "source": [
        "# First, let's import our required libraries\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty33-TJaWb6K"
      },
      "source": [
        "## Building the Markov Chain\n",
        "\n",
        "A Markov chain represents sequences of states where the probability of each state\n",
        "depends only on the previous state(s). In our case, each state will be a sequence\n",
        "of words, and we'll predict the next word based on this sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1hn3N4DcWb6K"
      },
      "outputs": [],
      "source": [
        "def build_markov_chain(text, order=2):\n",
        "    \"\"\"\n",
        "    Build a Markov chain from input text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to learn from\n",
        "        order (int): Number of words to use as state (context)\n",
        "\n",
        "    Returns:\n",
        "        dict: Mapping from state tuples to lists of possible next words\n",
        "    \"\"\"\n",
        "    chain = defaultdict(list)\n",
        "    words = text.split()\n",
        "\n",
        "    for i in range(len(words) - order):\n",
        "        # Create state tuple from current words\n",
        "        state = tuple(words[i:i+order])\n",
        "        # Get the next word\n",
        "        next_word = words[i+order]\n",
        "        # Add to chain\n",
        "        chain[state].append(next_word)\n",
        "\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPkYpOQzWb6K"
      },
      "source": [
        "## Generating Text\n",
        "\n",
        "Now we'll use our Markov chain to generate new text. We'll randomly select from\n",
        "the possible next words at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5Mz5irv0Wb6K"
      },
      "outputs": [],
      "source": [
        "def generate_text(chain, num_words=30):\n",
        "    \"\"\"\n",
        "    Generate new text using the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain mapping states to possible next words\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    # Start with a random state from the chain\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            next_word = random.choice(chain[state])\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_4BdqfkWb6K"
      },
      "source": [
        "## Part 3: Basic Example\n",
        "\n",
        "Let's try our text generator with a simple example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "La21t1fLWb6K",
        "outputId": "c3b7c464-7ce0-4456-a8ce-e1ace992c44c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick -> ['brown']\n",
            "quick brown -> ['fox', 'dog', 'dog']\n",
            "brown fox -> ['jumps']\n",
            "fox jumps -> ['over']\n",
            "jumps over -> ['the', 'the']\n",
            "over the -> ['lazy', 'lazy']\n",
            "the lazy -> ['dog.', 'fox.']\n",
            "lazy dog. -> ['A']\n",
            "dog. A -> ['quick']\n",
            "A quick -> ['brown']\n",
            "brown dog -> ['jumps', 'watches.']\n",
            "dog jumps -> ['over']\n",
            "lazy fox. -> ['The']\n",
            "fox. The -> ['lazy']\n",
            "The lazy -> ['fox']\n",
            "lazy fox -> ['sleeps']\n",
            "fox sleeps -> ['while']\n",
            "sleeps while -> ['the']\n",
            "while the -> ['quick']\n",
            "the quick -> ['brown']\n"
          ]
        }
      ],
      "source": [
        "# Sample text\n",
        "sample_text = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "A quick brown dog jumps over the lazy fox.\n",
        "The lazy fox sleeps while the quick brown dog watches.\n",
        "\"\"\"\n",
        "\n",
        "# Build the chain\n",
        "chain = build_markov_chain(sample_text)\n",
        "\n",
        "# Examine the chain\n",
        "for state, words in chain.items():\n",
        "    print(f\"{' '.join(state)} -> {words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KSvXoLlGWb6K",
        "outputId": "4863ed4e-c795-4ab6-8681-98f59f871fb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "lazy fox sleeps while the quick brown dog watches.\n"
          ]
        }
      ],
      "source": [
        "# Generate some text\n",
        "print(\"Generated text:\")\n",
        "print(generate_text(chain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leavwWBuWb6L"
      },
      "source": [
        "## Student Tasks\n",
        "\n",
        "1. Basic Implementation:\n",
        "   - Try changing the order parameter in build_markov_chain\n",
        "   - What happens with order=1 vs order=3?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qHw1Z1cnWb6L",
        "outputId": "0500aba5-164b-4729-f891-4f0dd92b98c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Order 1:\n",
            "dog watches.\n",
            "\n",
            "Order 3:\n",
            "lazy fox sleeps while the quick brown dog jumps over the lazy fox. The lazy fox sleeps while the quick brown dog watches.\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Experiment with different orders\n",
        "print(\"\\nOrder 1:\")\n",
        "chain1 = build_markov_chain(sample_text, order=1)\n",
        "print(generate_text(chain1))\n",
        "\n",
        "print(\"\\nOrder 3:\")\n",
        "chain3 = build_markov_chain(sample_text, order=3)\n",
        "print(generate_text(chain3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGdX6gC-Wb6L"
      },
      "source": [
        "2. Use Your Own Text:\n",
        "   Below, try using a different text source. You could use:\n",
        "   - Song lyrics\n",
        "   - Book excerpts\n",
        "   - Movie quotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "YFUn8rw2Wb6L",
        "outputId": "4096cd62-f9e5-4890-868f-92e65b7524e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She smiled -> ['Leapt,']\n",
            "smiled Leapt, -> ['without']\n",
            "Leapt, without -> ['looking']\n",
            "without looking -> ['And']\n",
            "looking And -> ['tumbled']\n",
            "And tumbled -> ['into']\n",
            "tumbled into -> ['the']\n",
            "into the -> ['Seine']\n",
            "the Seine -> ['The', 'Smiling']\n",
            "Seine The -> ['water']\n",
            "The water -> ['was']\n",
            "water was -> ['freezing']\n",
            "was freezing -> ['She']\n",
            "freezing She -> ['spent']\n",
            "She spent -> ['a']\n",
            "spent a -> ['month']\n",
            "a month -> ['sneezing']\n",
            "month sneezing -> ['But']\n",
            "sneezing But -> ['said']\n",
            "But said -> ['she']\n",
            "said she -> ['would']\n",
            "she would -> ['do']\n",
            "would do -> ['it']\n",
            "do it -> ['again', 'again']\n",
            "it again -> [\"Here's\"]\n",
            "again Here's -> ['to']\n",
            "Here's to -> ['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']\n",
            "to the -> ['ones', 'hearts', 'mess', 'ones', 'hearts', 'mess', 'fools', 'hearts', 'mess']\n",
            "the ones -> ['who', 'who']\n",
            "ones who -> ['dream', 'dream']\n",
            "who dream -> ['Foolish', 'Foolish', 'Crazy']\n",
            "dream Foolish -> ['as', 'as']\n",
            "Foolish as -> ['they', 'they']\n",
            "as they -> ['may', 'may', 'may']\n",
            "they may -> ['seem', 'seem', 'seem']\n",
            "may seem -> [\"Here's\", \"Here's\", \"Here's\"]\n",
            "seem Here's -> ['to', 'to', 'to']\n",
            "the hearts -> ['that', 'that', 'that']\n",
            "hearts that -> ['ache', 'ache', 'break']\n",
            "that ache -> [\"Here's\", \"Here's\"]\n",
            "ache Here's -> ['to', 'to']\n",
            "the mess -> ['we', 'we', 'we']\n",
            "mess we -> ['make', 'make', 'make']\n",
            "we make -> ['She', 'She', 'I']\n",
            "make She -> ['captured', 'told']\n",
            "She captured -> ['a']\n",
            "captured a -> ['feeling']\n",
            "a feeling -> ['Sky']\n",
            "feeling Sky -> ['with']\n",
            "Sky with -> ['no']\n",
            "with no -> ['ceiling']\n",
            "no ceiling -> ['The']\n",
            "ceiling The -> ['sunset']\n",
            "The sunset -> ['inside']\n",
            "sunset inside -> ['a']\n",
            "inside a -> ['frame']\n",
            "a frame -> ['She']\n",
            "frame She -> ['lived']\n",
            "She lived -> ['in']\n",
            "lived in -> ['her']\n",
            "in her -> ['liquor']\n",
            "her liquor -> ['And']\n",
            "liquor And -> ['died']\n",
            "And died -> ['with']\n",
            "died with -> ['a']\n",
            "with a -> ['flicker']\n",
            "a flicker -> [\"I'll\"]\n",
            "flicker I'll -> ['always']\n",
            "I'll always -> ['remember']\n",
            "always remember -> ['the']\n",
            "remember the -> ['flame']\n",
            "the flame -> [\"Here's\"]\n",
            "flame Here's -> ['to']\n",
            "She told -> ['me']\n",
            "told me -> ['\"A']\n",
            "me \"A -> ['bit']\n",
            "\"A bit -> ['of']\n",
            "bit of -> ['madness']\n",
            "of madness -> ['is']\n",
            "madness is -> ['key']\n",
            "is key -> ['To']\n",
            "key To -> ['give']\n",
            "To give -> ['us']\n",
            "give us -> ['new']\n",
            "us new -> ['colors']\n",
            "new colors -> ['to']\n",
            "colors to -> ['see']\n",
            "to see -> ['Who']\n",
            "see Who -> ['knows']\n",
            "Who knows -> ['where']\n",
            "knows where -> ['it']\n",
            "where it -> ['will']\n",
            "it will -> ['lead']\n",
            "will lead -> ['us?']\n",
            "lead us? -> ['And']\n",
            "us? And -> [\"that's\"]\n",
            "And that's -> ['why']\n",
            "that's why -> ['they']\n",
            "why they -> ['need']\n",
            "they need -> ['us\"']\n",
            "need us\" -> ['So']\n",
            "us\" So -> ['bring']\n",
            "So bring -> ['on']\n",
            "bring on -> ['the']\n",
            "on the -> ['rebels']\n",
            "the rebels -> ['The']\n",
            "rebels The -> ['ripples']\n",
            "The ripples -> ['from']\n",
            "ripples from -> ['pebbles']\n",
            "from pebbles -> ['The']\n",
            "pebbles The -> ['painters,']\n",
            "The painters, -> ['and']\n",
            "painters, and -> ['poets,']\n",
            "and poets, -> ['and']\n",
            "poets, and -> ['plays']\n",
            "and plays -> ['And']\n",
            "plays And -> [\"here's\"]\n",
            "And here's -> ['to']\n",
            "here's to -> ['the']\n",
            "the fools -> ['who']\n",
            "fools who -> ['dream']\n",
            "dream Crazy -> ['as']\n",
            "Crazy as -> ['they']\n",
            "that break -> [\"Here's\"]\n",
            "break Here's -> ['to']\n",
            "make I -> ['trace']\n",
            "I trace -> ['it']\n",
            "trace it -> ['all']\n",
            "it all -> ['back']\n",
            "all back -> ['to']\n",
            "back to -> ['then']\n",
            "to then -> ['Her,']\n",
            "then Her, -> ['and']\n",
            "Her, and -> ['the']\n",
            "and the -> ['snow,', 'Seine']\n",
            "the snow, -> ['and']\n",
            "snow, and -> ['the']\n",
            "Seine Smiling -> ['through']\n",
            "Smiling through -> ['it']\n",
            "through it -> ['She']\n",
            "it She -> ['said']\n",
            "She said -> [\"she'd\"]\n",
            "said she'd -> ['do']\n",
            "she'd do -> ['it']\n"
          ]
        }
      ],
      "source": [
        "# Task 2: Add your own text here\n",
        "your_text = \"\"\"\n",
        "\n",
        "She smiled\n",
        "Leapt, without looking\n",
        "And tumbled into the Seine\n",
        "The water was freezing\n",
        "She spent a month sneezing\n",
        "But said she would do it again\n",
        "Here's to the ones who dream\n",
        "Foolish as they may seem\n",
        "Here's to the hearts that ache\n",
        "Here's to the mess we make\n",
        "She captured a feeling\n",
        "Sky with no ceiling\n",
        "The sunset inside a frame\n",
        "She lived in her liquor\n",
        "And died with a flicker\n",
        "I'll always remember the flame\n",
        "Here's to the ones who dream\n",
        "Foolish as they may seem\n",
        "Here's to the hearts that ache\n",
        "Here's to the mess we make\n",
        "She told me\n",
        "\"A bit of madness is key\n",
        "To give us new colors to see\n",
        "Who knows where it will lead us?\n",
        "And that's why they need us\"\n",
        "So bring on the rebels\n",
        "The ripples from pebbles\n",
        "The painters, and poets, and plays\n",
        "And here's to the fools who dream\n",
        "Crazy as they may seem\n",
        "Here's to the hearts that break\n",
        "Here's to the mess we make\n",
        "I trace it all back to then\n",
        "Her, and the snow, and the Seine\n",
        "Smiling through it\n",
        "She said she'd do it again\n",
        "\"\"\"\n",
        "\n",
        "# Build my chain\n",
        "chain = build_markov_chain(your_text)\n",
        "\n",
        "# Examine my chain\n",
        "for state, words in chain.items():\n",
        "    print(f\"{' '.join(state)} -> {words}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nOrder 1:\")\n",
        "chain1 = build_markov_chain(your_text, order=1)\n",
        "print(generate_text(chain1))\n",
        "\n",
        "print(\"\\nOrder 3:\")\n",
        "chain3 = build_markov_chain(your_text, order=3)\n",
        "print(generate_text(chain3))"
      ],
      "metadata": {
        "id": "jIiqV0ZpZKmA",
        "outputId": "ded33534-f491-4dba-9399-8fcdcc402367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Order 1:\n",
            "Her, and the hearts that ache Here's to the flame Here's to the rebels The water was freezing She lived in her liquor And here's to the hearts that ache\n",
            "\n",
            "Order 3:\n",
            "frame She lived in her liquor And died with a flicker I'll always remember the flame Here's to the ones who dream Foolish as they may seem Here's to the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyKV_ZPXWb6L"
      },
      "source": [
        "3. Advanced Implementation:\n",
        "   Add temperature-based sampling to control randomness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "D2wlcgAcWb6L",
        "outputId": "293e7173-fc9c-477c-8da6-78745483628f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Low temperature (more predictable):\n",
            "bit of madness is key To give us new colors to see Who knows where it will lead us? And that's why they need us\" So bring on the rebels\n",
            "\n",
            "High temperature (more random):\n",
            "frame She lived in her liquor And died with a flicker I'll always remember the flame Here's to the hearts that ache Here's to the ones who dream Crazy as\n"
          ]
        }
      ],
      "source": [
        "def generate_text_with_temperature(chain, temperature=1.0, num_words=30):\n",
        "    \"\"\"\n",
        "    Generate text with temperature-based sampling.\n",
        "    Lower temperature = more conservative/predictable\n",
        "    Higher temperature = more random/creative\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain\n",
        "        temperature (float): Controls randomness (0.1 to 2.0 recommended)\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "    \"\"\"\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            # Count frequencies of next words\n",
        "            next_words = chain[state]\n",
        "            word_counts = defaultdict(int)\n",
        "            for word in next_words:\n",
        "                word_counts[word] += 1\n",
        "\n",
        "            # Apply temperature\n",
        "            weights = [count ** (1.0 / temperature) for count in word_counts.values()]\n",
        "            total = sum(weights)\n",
        "            weights = [w/total for w in weights]\n",
        "\n",
        "            # Choose next word based on weighted probabilities\n",
        "            next_word = random.choices(list(word_counts.keys()), weights=weights)[0]\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Try different temperatures\n",
        "print(\"\\nLow temperature (more predictable):\")\n",
        "print(generate_text_with_temperature(chain, temperature=3.0))\n",
        "\n",
        "print(\"\\nHigh temperature (more random):\")\n",
        "print(generate_text_with_temperature(chain, temperature=7.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRzTJu3cWb6L"
      },
      "source": [
        "## Challenge Tasks:\n",
        "\n",
        "1. Implement a function to analyze the Markov chain:\n",
        "   - Count the number of unique states\n",
        "   - Find the most common transitions\n",
        "   - Calculate the average number of possible next words for each state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl9DV_9CWb6L"
      },
      "outputs": [],
      "source": [
        "def analyze_chain(chain):\n",
        "    \"\"\"\n",
        "    Analyze properties of the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain to analyze\n",
        "    \"\"\"\n",
        "    num_states = len(chain)\n",
        "    total_transitions = sum(len(next_words) for next_words in chain.values())\n",
        "    avg_transitions = total_transitions / num_states if num_states > 0 else 0\n",
        "\n",
        "    # Find most common next word for each state\n",
        "    most_common = {}\n",
        "    for state, next_words in chain.items():\n",
        "        word_counts = defaultdict(int)\n",
        "        for word in next_words:\n",
        "            word_counts[word] += 1\n",
        "        most_common[state] = max(word_counts.items(), key=lambda x: x[1])\n",
        "\n",
        "    print(f\"Number of unique states: {num_states}\")\n",
        "    print(f\"Average transitions per state: {avg_transitions:.2f}\")\n",
        "    print(\"\\nMost common transitions:\")\n",
        "    for state, (word, count) in list(most_common.items())[:5]:  # Show top 5\n",
        "        print(f\"{' '.join(state)} -> {word} (count: {count})\")\n",
        "\n",
        "# Analyze our chain\n",
        "print(\"\\nChain Analysis:\")\n",
        "analyze_chain(chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-8gy3vqWb6L"
      },
      "source": [
        "## Further Exploration:\n",
        "\n",
        "Other ideas to try:\n",
        "1. Modify the code to preserve punctuation\n",
        "2. Add start-of-sentence and end-of-sentence tokens\n",
        "3. Implement bi-directional generation\n",
        "4. Create a chain that works with characters instead of words\n",
        "5. Add input validation and error handling"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "iat460",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}